{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import os.path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim import corpora\n",
    "from gensim.models import LsiModel\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Doc2Vec\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.rslp import RSLPStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\bruno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, file_name):\n",
    "    documents_list = []\n",
    "    with open(os.path.join(path, file_name) ,\"r\", encoding='utf8') as f:\n",
    "        for line in f.readlines():\n",
    "            text = line.strip()\n",
    "            if len(text) > 0:\n",
    "                documents_list.append(text)\n",
    "    \n",
    "    return documents_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(doc_set):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    stop = set(stopwords.words('portuguese'))\n",
    "    stemmer = RSLPStemmer()\n",
    "    \n",
    "    texts = []\n",
    "    for i in doc_set:\n",
    "        raw = unidecode(i).lower()\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "        stopped_tokens = [i for i in tokens if not i in stop]\n",
    "        stemmed_tokens = [stemmer.stem(i) for i in stopped_tokens]\n",
    "        texts.append(stemmed_tokens)\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_corpus(doc_clean):\n",
    "    dictionary = corpora.Dictionary(doc_clean)\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "\n",
    "    model = TfidfModel(corpus)\n",
    "\n",
    "    doc_term_matrix = [model[doc] for doc in corpus]\n",
    "\n",
    "    return dictionary, doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gensim_lsa_model(doc_clean, number_of_topics):\n",
    "    dictionary, doc_term_matrix = prepare_corpus(doc_clean)\n",
    "    lsamodel = LsiModel(doc_term_matrix, num_topics=number_of_topics, id2word=dictionary)\n",
    "\n",
    "    return lsamodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics(model, prep_text):\n",
    "    topics = model[prep_text]\n",
    "    total_topics = []\n",
    "    for topic in topics:\n",
    "        if len(topic) > 0:\n",
    "            total_topics.append([t[1] for t in topic])\n",
    "    \n",
    "    return np.array(total_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_doc = load_data(\"C:/Users/bruno/Documents/Projetos/TCC/ground-truth/1-facil\", \"correio da lavoura_1484_agosto de 1945-1.txt\")\n",
    "ocr_doc = load_data(\"C:/Users/bruno/Documents/Projetos/TCC/workspace/correio-da-lavoura-ocr/output/correio da lavoura_1484_agosto de 1945/page0001-1\", \"processed.txt\")\n",
    "clean_text = preprocess_data(gt_doc + ocr_doc)\n",
    "model = create_gensim_lsa_model(clean_text, number_of_topics=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_clean = preprocess_data(gt_doc)\n",
    "_, gt_prep = prepare_corpus(gt_clean)\n",
    "gt_topics = model[gt_prep]\n",
    "\n",
    "ocr_clean = preprocess_data(ocr_doc)\n",
    "_, ocr_prep = prepare_corpus(ocr_clean)\n",
    "ocr_topics = model[ocr_prep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05207200169035882"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_topics = get_topics(model, gt_prep)\n",
    "ocr_topics = get_topics(model, ocr_prep)\n",
    "np.mean(cosine_similarity(gt_topics, ocr_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_doc = load_data(\"C:/Users/bruno/Documents/Projetos/TCC/ground-truth/1-facil\", \"correio da lavoura_1484_agosto de 1945-1.txt\")\n",
    "ocr_doc = load_data(\"C:/Users/bruno/Documents/Projetos/TCC/workspace/correio-da-lavoura-ocr/output/correio da lavoura_1484_agosto de 1945/page0001-2\", \"base.txt\")\n",
    "clean_text = preprocess_data(gt_doc + ocr_doc)\n",
    "model = Word2Vec(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306, 100)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_clean = preprocess_data(gt_doc)\n",
    "gt_flat = [item for sublist in gt_clean for item in sublist]\n",
    "gt_vector = np.array([model.wv[word] for word in gt_flat if word in model.wv])\n",
    "gt_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213, 100)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_clean = preprocess_data(ocr_doc)\n",
    "ocr_flat = [item for sublist in ocr_clean for item in sublist]\n",
    "ocr_vector = np.array([model.wv[word] for word in ocr_flat if word in model.wv])\n",
    "ocr_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(model, s):\n",
    "    return np.sum(np.array([model[i] for i in s if i in model]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100,), (100,))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_vector = get_vector(model.wv, gt_flat)\n",
    "ocr_vector = get_vector(model.wv, ocr_flat)\n",
    "gt_vector.shape, ocr_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55814326"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cosine_similarity(gt_vector.reshape(1,-1), ocr_vector.reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treinar Word2Vec em todos os ground-truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package mac_morpho to\n",
      "[nltk_data]     C:\\Users\\bruno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package mac_morpho is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51397"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import mac_morpho\n",
    "nltk.download('mac_morpho')\n",
    "len(mac_morpho.paras())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "003ac9aaa1485d5b771c302278ee1fa2d675754790301e4c4d0b7cf7d8ab189c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
